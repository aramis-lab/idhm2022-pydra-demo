{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741ee8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from typing import BinaryIO, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "def find_clinical_data(clinical_data_directory: PathLike) -> Optional[DataFrame]:\n",
    "    from pathlib import Path\n",
    "\n",
    "    from pandas import read_excel\n",
    "\n",
    "    dataframe = None\n",
    "    for path in Path(clinical_data_directory).rglob(\"*.xlsx\"):\n",
    "        try:\n",
    "            dataframe = (\n",
    "                read_excel(path, index_col=[0, 4])  # noqa\n",
    "                .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "                .rename_axis(index=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "                .convert_dtypes()\n",
    "                .sort_index()\n",
    "            )\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def find_collection_data(imaging_data_directory: PathLike) -> Optional[DataFrame]:\n",
    "    from pathlib import Path\n",
    "\n",
    "    from pandas import read_csv\n",
    "\n",
    "    dataframe = None\n",
    "    for path in Path(imaging_data_directory).rglob(\"*.csv\"):\n",
    "        try:\n",
    "            dataframe = (\n",
    "                read_csv(\n",
    "                    path,\n",
    "                    index_col=\"Image Data ID\",\n",
    "                    parse_dates=[\"Acq Date\"],\n",
    "                )\n",
    "                .rename(columns=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "                .rename_axis(index=lambda x: x.lower().replace(\" \", \"_\"))\n",
    "                .convert_dtypes()\n",
    "                .sort_index()\n",
    "            )\n",
    "        except (ValueError, IndexError):\n",
    "            continue\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def find_imaging_data(imaging_data_directory: PathLike) -> Iterable[Tuple[str, str]]:\n",
    "    import re\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Pattern for extracting the image data ID from the NIFD files.\n",
    "    pattern = re.compile(r\"(I\\d{6})\")\n",
    "\n",
    "    def find_files(in_: PathLike) -> Iterable[Path]:\n",
    "        return filter(lambda x: x.is_file(), Path(in_).rglob(\"NIFD*.*\"))\n",
    "\n",
    "    def extract_id_with_dir(files: Iterable[Path]) -> Tuple[str, str]:\n",
    "        for f in files:\n",
    "            found = pattern.search(f.name)\n",
    "            if found:\n",
    "                yield found.group(1), str(f.parent)\n",
    "\n",
    "    for image_data_id, source_dir in set(\n",
    "        sorted(extract_id_with_dir(find_files(imaging_data_directory)))\n",
    "    ):\n",
    "        yield image_data_id, source_dir\n",
    "\n",
    "\n",
    "def parse_mri_description(description: str) -> Optional[Dict[str, Optional[str]]]:\n",
    "    description = description.lower().replace(\"-\", \"\")\n",
    "\n",
    "    if \"mprage\" in description:\n",
    "        return {\n",
    "            \"datatype\": \"anat\",\n",
    "            \"suffix\": \"T1w\",\n",
    "            \"trc_label\": None,\n",
    "            \"rec_label\": None,\n",
    "        }\n",
    "    elif \"flair\" in description:\n",
    "        return {\n",
    "            \"datatype\": \"anat\",\n",
    "            \"suffix\": \"FLAIR\",\n",
    "            \"trc_label\": None,\n",
    "            \"rec_label\": None,\n",
    "        }\n",
    "    elif \"t2\" in description:\n",
    "        return {\n",
    "            \"datatype\": \"anat\",\n",
    "            \"suffix\": \"T2w\",\n",
    "            \"trc_label\": None,\n",
    "            \"rec_label\": None,\n",
    "        }\n",
    "    elif \"asl\" in description:\n",
    "        return {\n",
    "            \"datatype\": \"anat\",\n",
    "            \"suffix\": \"PDw\",\n",
    "            \"trc_label\": None,\n",
    "            \"rec_label\": None,\n",
    "        }\n",
    "    elif any([x in description for x in [\"mt1\", \"gradwarp\", \"n3m\"]]):\n",
    "        return {\n",
    "            \"datatype\": \"anat\",\n",
    "            \"suffix\": \"T1w\",\n",
    "            \"trc_label\": None,\n",
    "            \"rec_label\": None,\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_pet_description(description: str) -> Optional[Dict[str, str]]:\n",
    "    import re\n",
    "\n",
    "    match = re.search(r\"3D:(\\w+):(\\w+)\", description)\n",
    "\n",
    "    if match:\n",
    "        return {\n",
    "            \"datatype\": \"pet\",\n",
    "            \"suffix\": \"pet\",\n",
    "            \"trc_label\": \"11CPIB\" if \"PIB\" in match.group(1) else \"18FFDG\",\n",
    "            \"rec_label\": \"IR\" if \"IR\" in match.group(2) else \"RP\",\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_preprocessing(description: str) -> dict:\n",
    "    description = description.lower()\n",
    "\n",
    "    return {\n",
    "        \"gradwarp\": any([x in description for x in [\"gradwarp\", \"dis3d\"]]),\n",
    "        \"n3\": \"n3m\" in description,\n",
    "    }\n",
    "\n",
    "\n",
    "def write_to_tsv(dataframe: DataFrame, buffer: Union[PathLike, BinaryIO]) -> None:\n",
    "    # Save dataframe as a BIDS-compliant TSV file.\n",
    "    dataframe.to_csv(buffer, sep=\"\\t\", na_rep=\"n/a\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def run_dcm2niix(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    output_fmt: str,\n",
    "    compress: bool = False,\n",
    "    bids_sidecar: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Runs the dcm2niix command using a subprocess.\n",
    "\n",
    "    Args: the dcm2niix command with the right arguments.\n",
    "    \"\"\"\n",
    "    import subprocess\n",
    "\n",
    "    #from clinica.utils.stream import cprint\n",
    "\n",
    "    command = [\"dcm2niix\", \"-w\", \"0\", \"-f\", output_fmt, \"-o\", output_dir]\n",
    "    command += [\"-9\", \"-z\", \"y\"] if compress else [\"-z\", \"n\"]\n",
    "    command += [\"-b\", \"y\", \"-ba\", \"y\"] if bids_sidecar else [\"-b\", \"n\"]\n",
    "    command += [input_dir]\n",
    "\n",
    "    completed_process = subprocess.run(command, capture_output=True)\n",
    "\n",
    "    if completed_process.returncode != 0:\n",
    "        print(\n",
    "                f\"DICOM to BIDS conversion with dcm2niix failed:\\n\"\n",
    "                f\"command: {command}\\n\"\n",
    "                f\"{completed_process.stdout.decode('utf-8')}\"  \n",
    "        )\n",
    "\n",
    "\n",
    "def convert_dicom(sourcedata_dir: PathLike, bids_filename: PathLike) -> None:\n",
    "    from pathlib import PurePath\n",
    "\n",
    "    from fsspec.implementations.local import LocalFileSystem\n",
    "\n",
    "    #from clinica.iotools.bids_utils import run_dcm2niix\n",
    "\n",
    "    output_fmt = str(PurePath(bids_filename).name).replace(\".nii.gz\", \"\")\n",
    "    output_dir = str(PurePath(bids_filename).parent)\n",
    "\n",
    "    # Ensure output directory is empty.\n",
    "    fs = LocalFileSystem()\n",
    "    if fs.exists(output_dir):\n",
    "        fs.rm(output_dir, recursive=True)\n",
    "    fs.makedirs(output_dir)\n",
    "\n",
    "    # Run conversion with dcm2niix with anonymization and maximum compression.\n",
    "    run_dcm2niix(\n",
    "        input_dir=str(sourcedata_dir),\n",
    "        output_dir=output_dir,\n",
    "        output_fmt=output_fmt,\n",
    "        compress=True,\n",
    "        bids_sidecar=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def install_nifti(sourcedata_dir: PathLike, bids_filename: PathLike) -> None:\n",
    "    from fsspec.implementations.local import LocalFileSystem\n",
    "\n",
    "    fs = LocalFileSystem(auto_mkdir=True)\n",
    "    source_file = fs.open(fs.ls(str(sourcedata_dir))[0], mode=\"rb\")\n",
    "    target_file = fs.open(str(bids_filename), mode=\"wb\", compression=\"gzip\")\n",
    "\n",
    "    with source_file as sf, target_file as tf:\n",
    "        tf.write(sf.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from typing import BinaryIO, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "from pandas import DataFrame\n",
    "from pydra.mark import annotate, task\n",
    "\n",
    "\n",
    "@task\n",
    "@annotate({\"return\":{\"dataframe\": DataFrame}})\n",
    "def read_clinical_data(clinical_data_directory: PathLike) -> DataFrame:\n",
    "    import pandas as pd\n",
    "\n",
    "    dataframe = find_clinical_data(clinical_data_directory)\n",
    "\n",
    "    if dataframe is None:\n",
    "        raise FileNotFoundError(\"Clinical data not found\")\n",
    "\n",
    "    # Compute participant and session IDs.\n",
    "    dataframe = dataframe.rename_axis(\n",
    "        index={\"loni_id\": \"participant_id\", \"visit_number\": \"session_id\"}\n",
    "    )\n",
    "    dataframe.index = dataframe.index.map(\n",
    "        lambda x: (f\"sub-NIFD{x[0].replace('_', '')}\", f\"ses-M{(6 * (x[1] - 1)):03d}\")\n",
    "    )\n",
    "\n",
    "    # Keep relevant columns and rename them.\n",
    "    dataframe = (\n",
    "        dataframe[[\"dx\", \"site\", \"education\", \"race\", \"cdr_box_score\", \"mmse_tot\"]]\n",
    "        .rename(columns={\"dx\": \"diagnosis\", \"cdr_box_score\": \"cdr\", \"mmse_tot\": \"mmse\"})\n",
    "        .astype(\n",
    "            dtype={\n",
    "                \"diagnosis\": pd.CategoricalDtype(\n",
    "                    [\"BV\", \"CON\", \"L_SD\", \"PATIENT (OTHER)\", \"PNFA\", \"SV\"]\n",
    "                ),\n",
    "                \"site\": pd.CategoricalDtype([\"UCSF\", \"MAYO\", \"MGH\"]),\n",
    "                \"education\": pd.Int64Dtype(),\n",
    "                \"race\": pd.Int64Dtype(),\n",
    "                \"cdr\": pd.Float64Dtype(),\n",
    "                \"mmse\": pd.Float64Dtype(),\n",
    "            }\n",
    "        )\n",
    "        .replace({\"education\": {99: pd.NA}, \"race\": {50: pd.NA, 99: pd.NA}})\n",
    "    )\n",
    "\n",
    "    # Keep positive MMSE values only.\n",
    "    dataframe.mmse = dataframe.mmse.mask(dataframe.mmse < 0)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "@task\n",
    "@annotate({\"return\": {\"dataframe\": DataFrame}})\n",
    "def read_imaging_data(imaging_data_directory: PathLike) -> DataFrame:\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    try:\n",
    "        imaging_data = DataFrame.from_records(\n",
    "            data=find_imaging_data(imaging_data_directory),\n",
    "            columns=[\"image_data_id\", \"source_dir\"],\n",
    "            index=\"image_data_id\",\n",
    "        ).convert_dtypes()\n",
    "    except TypeError:\n",
    "        raise FileNotFoundError(\"No imaging data found\")\n",
    "\n",
    "    collection_data = find_collection_data(imaging_data_directory)\n",
    "\n",
    "    if collection_data is None:\n",
    "        raise FileNotFoundError(\"No collection data found\")\n",
    "    dataframe = collection_data.join(imaging_data)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "@task\n",
    "@annotate({\"return\": {\"subjects\": DataFrame, \"sessions\": DataFrame, \"scans\": DataFrame}})\n",
    "def dataset_to_bids(\n",
    "    imaging_data: DataFrame,\n",
    "    clinical_data: Optional[DataFrame] = None,\n",
    ") -> Tuple[DataFrame, DataFrame, DataFrame]:\n",
    "    from pandas import Series\n",
    "\n",
    "    # Parse preprocessing information from scan descriptions.\n",
    "    preprocessing = imaging_data.description.apply(parse_preprocessing).apply(Series)\n",
    "\n",
    "    # Parse BIDS entities from scan descriptions.\n",
    "    bids = (\n",
    "        imaging_data.apply(\n",
    "            lambda x: parse_pet_description(x.description)\n",
    "            if x.modality == \"PET\"\n",
    "            else parse_mri_description(x.description),\n",
    "            axis=1,\n",
    "        )\n",
    "        .dropna()\n",
    "        .apply(Series)\n",
    "    )\n",
    "\n",
    "    # Compute quality metric for each scan:\n",
    "    # - MRI: Applied preprocessing (0: None, 1: GradWarp, 2: N3)\n",
    "    # - PET: Reconstruction method (0: Fourier, 1: Iterative)\n",
    "    quality = (\n",
    "        preprocessing.sum(axis=1)\n",
    "        + bids.rec_label.apply(lambda x: 1 if x == \"IR\" else 0)\n",
    "    ).rename(\"quality\")\n",
    "\n",
    "    # Select one scan per BIDS modality based on quality metric.\n",
    "    subset = [\"subject\", \"visit\", \"datatype\", \"suffix\", \"trc_label\"]\n",
    "    scans = (\n",
    "        bids.join(quality)\n",
    "        .join(imaging_data)\n",
    "        .sort_values(by=subset + [\"quality\"])\n",
    "        .drop_duplicates(subset=subset, keep=\"last\")\n",
    "        .drop(columns=\"quality\")\n",
    "    )\n",
    "\n",
    "    # Compute the BIDS-compliant participant, session and scan IDs.\n",
    "    scans = scans.assign(\n",
    "        participant_id=lambda df: df.subject.apply(\n",
    "            lambda x: f\"sub-NIFD{x.replace('_', '')}\"\n",
    "        ),\n",
    "        session_id=lambda df: df.visit.apply(lambda x: f\"ses-M{(6 * (x - 1)):03d}\"),\n",
    "        filename=lambda df: df.apply(\n",
    "            lambda x: f\"{x.participant_id}/{x.session_id}/{x.datatype}/\"\n",
    "            f\"{x.participant_id}_{x.session_id}\"\n",
    "            f\"{'_trc-' + x.trc_label if x.trc_label else ''}\"\n",
    "            f\"{'_rec-' + x.rec_label if x.rec_label else ''}\"\n",
    "            f\"_{x.suffix}.nii.gz\",\n",
    "            axis=1,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Prepare subjects manifest.\n",
    "    subjects = (\n",
    "        scans[[\"participant_id\", \"session_id\", \"group\", \"sex\", \"age\"]]\n",
    "        .sort_values(by=[\"participant_id\", \"session_id\"])\n",
    "        .drop(columns=\"session_id\")\n",
    "        .drop_duplicates(subset=\"participant_id\")\n",
    "        .set_index([\"participant_id\"], verify_integrity=True)\n",
    "        .sort_index()\n",
    "    ).join(\n",
    "        clinical_data.xs(\"ses-M000\", level=\"session_id\")[\n",
    "            [\"diagnosis\", \"site\", \"education\", \"race\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Prepare sessions manifest.\n",
    "    sessions = (\n",
    "        scans[[\"participant_id\", \"session_id\", \"acq_date\", \"age\"]]\n",
    "        .rename(columns={\"acq_date\": \"date\"})\n",
    "        .drop_duplicates()\n",
    "        .set_index([\"participant_id\", \"session_id\"], verify_integrity=True)\n",
    "        .sort_index()\n",
    "    ).join(clinical_data[[\"cdr\", \"mmse\"]])\n",
    "\n",
    "    # Prepare scans manifest.\n",
    "    scans = scans[[\"filename\", \"source_dir\", \"format\"]].set_index(\n",
    "        \"filename\", verify_integrity=True\n",
    "  )\n",
    "    #scans= scans[\"filename\"].tolist()\n",
    "    print(\"subjects: \", subjects)\n",
    "    print(\"sessions: \", sessions)\n",
    "    \n",
    "    print(\"scans: \", scans)\n",
    "    \n",
    "    return subjects, sessions, scans\n",
    "\n",
    "@task\n",
    "@annotate({\"return\": {\"some_list\": List}})\n",
    "def write_bids(\n",
    "    to: PathLike,\n",
    "    participants: DataFrame,\n",
    "    sessions: DataFrame,\n",
    "    scans: DataFrame,\n",
    ") -> List[PathLike]:\n",
    "    from pathlib import PurePath\n",
    "\n",
    "    from fsspec.implementations.local import LocalFileSystem\n",
    "\n",
    "    #from clinica.iotools.bids_dataset_description import BIDSDatasetDescription\n",
    "\n",
    "    to = PurePath(to)\n",
    "    fs = LocalFileSystem(auto_mkdir=True)\n",
    "\n",
    "    # Ensure BIDS hierarchy is written first.\n",
    "    with fs.transaction:\n",
    "        #with fs.open(\n",
    "         #   str(to / \"dataset_description.json\"), \"w\"\n",
    "        #) #as dataset_description_file:\n",
    "           # BIDSDatasetDescription(name=\"NIFD\").write(to=dataset_description_file)\n",
    "        with fs.open(str(to / \"participants.tsv\"), \"w\") as participant_file:\n",
    "            write_to_tsv(participants, participant_file)\n",
    "\n",
    "        for participant_id, sessions_group in sessions.groupby(\"participant_id\"):\n",
    "            participant_id = str(participant_id)\n",
    "            sessions_group = sessions_group.droplevel(\"participant_id\")\n",
    "            sessions_filepath = to / participant_id / f\"{participant_id}_sessions.tsv\"\n",
    "            with fs.open(str(sessions_filepath), \"w\") as sessions_file:\n",
    "                write_to_tsv(sessions_group, sessions_file)\n",
    "\n",
    "    # Perform import of imaging data next.\n",
    "    for filename, metadata in scans.iterrows():\n",
    "        filename = str(filename)\n",
    "        if metadata.format == \"DCM\":\n",
    "            convert_dicom(\n",
    "                sourcedata_dir=metadata.source_dir, bids_filename=to / filename\n",
    "            )\n",
    "        else:\n",
    "            install_nifti(\n",
    "                sourcedata_dir=metadata.source_dir, bids_filename=to / filename\n",
    "            )\n",
    "    some_list = scans.index.to_list()\n",
    "    #some_list = [0,1]\n",
    "    return some_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d66402",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert the NIFD dataset into BIDS.\"\"\"\n",
    "\n",
    "from os import PathLike\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def convert_images(\n",
    "    path_to_dataset: PathLike,\n",
    "    bids_dir: PathLike,\n",
    "    path_to_clinical: PathLike,\n",
    ") -> List[PathLike]:\n",
    "    \"\"\"Convert the entire dataset in BIDS.\n",
    "\n",
    "    Scans available files in the path_to_dataset,\n",
    "    identifies the patients that have images described by the JSON file,\n",
    "    converts the image with the highest quality for each category.\n",
    "    \"\"\"\n",
    "\n",
    "    #import clinica.iotools.bids_utils as bids\n",
    "    \n",
    "    from pydra import Workflow\n",
    "    \n",
    "    wf = Workflow(name = \"nifd_to_bids\", \n",
    "                  input_spec = [\"path_to_dataset\", \"bids_dir\", \"path_to_clinical\"],\n",
    "                  path_to_dataset = path_to_dataset,\n",
    "                  bids_dir = bids_dir,\n",
    "                  path_to_clinical = path_to_clinical,\n",
    "                 )\n",
    "    wf.add(\n",
    "        read_clinical_data(\n",
    "            name= \"read_clinical_data\",\n",
    "            clinical_data_directory = wf.lzin.path_to_clinical,\n",
    "        ) \n",
    "    )\n",
    "    #clinical_data = read_clinical_data(path_to_clinical)\n",
    "    wf.add(\n",
    "        read_imaging_data(\n",
    "        name = \"read_imaging_data\",\n",
    "        imaging_data_directory = wf.lzin.path_to_dataset,\n",
    "        )\n",
    "    )\n",
    "    #imaging_data = read_imaging_data(path_to_dataset)\n",
    "    wf.add(\n",
    "        dataset_to_bids(\n",
    "        name = \"dataset_to_bids\",\n",
    "        imaging_data = wf.read_imaging_data.lzout.dataframe,\n",
    "        clinical_data = wf.read_clinical_data.lzout.dataframe,\n",
    "        )\n",
    "    )\n",
    "    #participants, sessions, scans = dataset_to_bids(\n",
    "     #   imaging_data=imaging_data, clinical_data=clinical_data\n",
    "    #)\n",
    "    \n",
    "#    written = write_bids(\n",
    " #       to=bids_dir,\n",
    "  #      participants=participants,\n",
    "   #     sessions=sessions,\n",
    "    #    scans=scans,\n",
    "    #)\n",
    "    \n",
    "# readme_data = {\n",
    "#         \"link\": \"https://ida.loni.usc.edu/home/projectPage.jsp?project=NIFD&page=HOME&subPage=OVERVIEW_PR#\",\n",
    "#         \"desc\": (\n",
    "#             \"NIFD is the nickname for the frontotemporal lobar degeneration neuroimaging initiative \"\n",
    "#             \"(FTLDNI, AG032306), which was funded by the NIA and NINDS to characterize longitudinal clinical and \"\n",
    "#             \"imaging changes in FTLD.The imaging and clinical methods are the same for NIFD and for the 4-Repeat \"\n",
    "#             \"Tauopathy Neuroimaging Initiative (4RTNI), which is also available for download from LONI. Controls for \"\n",
    "#             \"NIFD are the same controls as those collected for 4RTNI.\"\n",
    "#         ),\n",
    "#     }\n",
    "#     bids.write_modality_agnostic_files(\n",
    "#         study_name=\"NIFD\", readme_data=readme_data, bids_dir=bids_dir\n",
    "#     )\n",
    "    wf.add(\n",
    "        write_bids(\n",
    "        name= \"write_bids\",\n",
    "        to=wf.lzin.bids_dir,\n",
    "        participants=wf.dataset_to_bids.lzout.subjects,\n",
    "        sessions=wf.dataset_to_bids.lzout.sessions,\n",
    "        scans=wf.dataset_to_bids.lzout.scans,\n",
    "        )\n",
    "    )\n",
    "    wf.set_output([\n",
    "        #(\"out\", wf.dataset_to_bids.lzout.scans),\n",
    "        (\"written\", wf.write_bids.lzout.some_list),\n",
    "    ])\n",
    "    return wf\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50100a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3168140",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_dir = \"/Users/matthieu.joulot/Documents/converter/Nifd2Bids/in/unorganized\"\n",
    "clinical_data_dir = \"/Users/matthieu.joulot/Documents/converter/Nifd2Bids/in/clinical_data\"\n",
    "bids_dir= \"/Users/matthieu.joulot/Documents/converter/Nifd2Bids/bids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c870cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = convert_images(imaging_dir, bids_dir, clinical_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wf(wf):\n",
    "    from pydra import Submitter\n",
    "    with Submitter(plugin=\"cf\") as submitter:\n",
    "        submitter(wf)\n",
    "        \n",
    "    return wf.result()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367037f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_wf(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bdadb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
